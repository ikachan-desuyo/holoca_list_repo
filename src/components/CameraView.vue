<template>
  <div>
    <button v-if="!cameraActive && opencvReady" @click="startCamera">ğŸ“¸ ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•</button>
    <video ref="videoRef" autoplay muted playsinline style="display:none"></video>
    <canvas
      ref="canvasRef"
      style="display:block; margin-top:12px; width:100%; max-width:400px; border:1px solid #ccc;"
    ></canvas>
    <div v-if="!opencvReady" style="color:#f00; margin-top:12px;">OpenCV.js èª­ã¿è¾¼ã¿ä¸­...</div>
    <div v-if="errorMsg" style="color:#f00; margin-top:12px; white-space:pre-wrap;">{{ errorMsg }}</div>
    <div v-if="recognizedCard" style="color:#080; margin-top:12px;">èªè­˜çµæœ: {{ recognizedCard }}</div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted } from 'vue'

const videoRef = ref<HTMLVideoElement>()
const canvasRef = ref<HTMLCanvasElement>()
const cameraActive = ref(false)
const opencvReady = ref(false)
const errorMsg = ref('')
const features = ref<any[]>([])
const recognizedCard = ref('')
let stream: MediaStream | null = null

// OpenCV.jsãƒ­ãƒ¼ãƒ‰æ¤œçŸ¥
onMounted(async () => {
  function checkOpenCV() {
    if (window.cv && cv.Mat) {
      opencvReady.value = true
    } else {
      opencvReady.value = false
    }
  }
  const scripts = document.getElementsByTagName('script')
  for (let i = 0; i < scripts.length; i++) {
    const s = scripts[i]
    if (s.src && s.src.includes('opencv.js')) {
      s.addEventListener('load', checkOpenCV)
    }
  }
  setTimeout(checkOpenCV, 2000)
  checkOpenCV()

  // features.jsonã®èª­ã¿è¾¼ã¿ï¼ˆVite/GitHub Pageså¯¾å¿œï¼‰
  try {
    const baseUrl = import.meta.env.BASE_URL || '/'
    const res = await fetch(baseUrl + 'features.json')
    features.value = await res.json()
  } catch (e) {
    errorMsg.value = 'features.jsonã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ\n' + (e instanceof Error ? e.message : String(e))
  }
})

async function startCamera() {
  errorMsg.value = ''
  recognizedCard.value = ''
  if (stream) {
    stream.getTracks().forEach(track => track.stop())
  }
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "environment" }
    })
    if (videoRef.value) {
      videoRef.value.srcObject = stream
      await videoRef.value.play()
      cameraActive.value = true
      startDrawingLoop()
    }
  } catch (err) {
    try {
      stream = await navigator.mediaDevices.getUserMedia({ video: true })
      if (videoRef.value) {
        videoRef.value.srcObject = stream
        await videoRef.value.play()
        cameraActive.value = true
        startDrawingLoop()
      }
    } catch (err2) {
      errorMsg.value = 'ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸ\n' + (err2 instanceof Error ? err2.message : String(err2))
    }
  }
}

function startDrawingLoop() {
  const video = videoRef.value!
  const canvas = canvasRef.value!
  const ctx = canvas.getContext('2d')!

  function waitForVideoReady() {
    if (video.videoWidth > 0 && video.videoHeight > 0) {
      canvas.width = video.videoWidth
      canvas.height = video.videoHeight
      loop()
    } else {
      requestAnimationFrame(waitForVideoReady)
    }
  }

  function loop() {
    ctx.clearRect(0, 0, canvas.width, canvas.height)
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height)

    try {
      if (window.cv && cv.Mat) {
        // --- OpenCVç”»åƒå‡¦ç† ---
        let src: any
        try {
          src = cv.imread(canvas)
          if (!src || src.empty()) {
            throw new Error('cv.imread(canvas) ã§ç”»åƒã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ')
          }
        } catch (e) {
          errorMsg.value = 'cv.imread(canvas) ã§å¤±æ•—ã—ã¾ã—ãŸ\n' + (e instanceof Error ? e.message : String(e))
          requestAnimationFrame(loop)
          return
        }

        const gray = new cv.Mat()
        const edges = new cv.Mat()
        try {
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY)
          cv.Canny(gray, edges, 50, 150)
        } catch (e) {
          errorMsg.value = 'OpenCVç”»åƒå‡¦ç†ã§å¤±æ•—ã—ã¾ã—ãŸ\n' + (e instanceof Error ? e.message : String(e))
          src.delete()
          gray.delete()
          edges.delete()
          requestAnimationFrame(loop)
          return
        }

        // ã‚¨ãƒƒã‚¸ç”»åƒã‚’RGBAã«å¤‰æ›ã—ã¦é‡ã­æç”»
        try {
          const rgba = new cv.Mat()
          cv.cvtColor(edges, rgba, cv.COLOR_GRAY2RGBA)
          const edgeImageData = new ImageData(
            new Uint8ClampedArray(rgba.data),
            rgba.cols,
            rgba.rows
          )
          ctx.save()
          ctx.globalAlpha = 0.5
          ctx.putImageData(edgeImageData, 0, 0)
          ctx.restore()
          rgba.delete()
        } catch (e) {
          errorMsg.value = 'ImageDataç”Ÿæˆã¾ãŸã¯æç”»ã§å¤±æ•—ã—ã¾ã—ãŸ\n' + (e instanceof Error ? e.message : String(e))
        }

        // --- ã‚«ãƒ¼ãƒ‰èªè­˜ ---
        try {
          if (features.value.length > 0) {
            recognizeCard(gray)
          }
        } catch (e) {
          errorMsg.value = 'ã‚«ãƒ¼ãƒ‰èªè­˜å‡¦ç†ã§å¤±æ•—ã—ã¾ã—ãŸ\n' + (e instanceof Error ? e.message : String(e))
        }

        src.delete()
        gray.delete()
        edges.delete()
      } else {
        ctx.font = 'bold 32px sans-serif'
        ctx.fillStyle = '#f00'
        ctx.fillText('OpenCV loading...', 30, 50)
      }
    } catch (e) {
      errorMsg.value = 'OpenCV error!\n' + (e instanceof Error ? e.message : String(e))
    }

    requestAnimationFrame(loop)
  }

  waitForVideoReady()
}

// ã‚«ãƒ¼ãƒ‰èªè­˜å‡¦ç†
function recognizeCard(gray: any) {
  // ORBç‰¹å¾´é‡æŠ½å‡º
  const orb = new cv.ORB()
  const keypoints = new cv.KeyPointVector()
  const descriptors = new cv.Mat()
  orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptors)

  let bestMatchIdx = -1
  let bestMatchCount = 0

  for (let idx = 0; idx < features.value.length; idx++) {
    const feature = features.value[idx]
    // DBå´ã®descriptorsã‚’Matã«å¤‰æ›
    const dbDescArr = feature.descriptors.flat()
    const dbDescriptors = cv.matFromArray(
      feature.descriptors.length,
      feature.descriptors[0].length,
      cv.CV_8U,
      dbDescArr
    )
    const bf = new cv.BFMatcher(cv.NORM_HAMMING, true)
    const matches = new cv.DMatchVector()
    bf.match(descriptors, dbDescriptors, matches)
    if (matches.size() > bestMatchCount) {
      bestMatchCount = matches.size()
      bestMatchIdx = idx
    }
    dbDescriptors.delete()
    matches.delete()
    bf.delete()
  }

  descriptors.delete()
  keypoints.delete()
  orb.delete()

  if (bestMatchIdx >= 0 && bestMatchCount > 10) { // ãƒãƒƒãƒæ•°é–¾å€¤ã¯é©å®œèª¿æ•´
    recognizedCard.value = features.value[bestMatchIdx].name + `ï¼ˆãƒãƒƒãƒæ•°: ${bestMatchCount}ï¼‰`
  } else {
    recognizedCard.value = 'èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ'
  }
}
</script>